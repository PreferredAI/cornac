{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uxfPR6vG5GP0"
      },
      "source": [
        "*Copyright (c) Cornac Authors. All rights reserved.*\n",
        "\n",
        "*Licensed under the Apache 2.0 License.*\n",
        "\n",
        "# Visual Bayesian Personalized Ranking with Text Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G0R8gyyt5GP4"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/PreferredAI/cornac/blob/master/tutorials/vbpr_text.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/PreferredAI/cornac/blob/master/tutorials/vbpr_text.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TURsVngV5GP5"
      },
      "source": [
        "## Overview\n",
        "\n",
        "We would like to use [Visual Bayesian Personalizer Ranking (VBPR)](https://arxiv.org/pdf/1510.01784.pdf), the model makes use of pre-trained visual features extracted from CNN. However, our data of interest [MovieLens dataset](https://grouplens.org/datasets/movielens/) does not come with visual information, but instead it contains text movie plots. In this tutorial, we will employ Conac's modality infrastructures to easily utilize VBPR to leverage item text content.\n",
        "\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "d7087AnL5Jte"
      },
      "outputs": [],
      "source": [
        "# install Cornac and PyTorch (VBPR model implementation uses PyTorch)\n",
        "!pip3 install cornac torch>=0.4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "8e1edON-5GP7",
        "outputId": "f609c795-cadb-45d5-fab1-25a0879853ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\ProgramFiles\\Anaconda\\envs\\cornac\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cornac version: 2.2.2\n"
          ]
        }
      ],
      "source": [
        "import cornac\n",
        "from cornac.data import Reader\n",
        "from cornac.datasets import movielens\n",
        "from cornac.eval_methods import RatioSplit\n",
        "from cornac.data import TextModality, ImageModality\n",
        "from cornac.data.text import BaseTokenizer\n",
        "\n",
        "print(\"Cornac version: {}\".format(cornac.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H8OadBhB5GQE"
      },
      "source": [
        "## Prepare data\n",
        "Here we use the MovieLens 100K dataset which is already accessible from Cornac. Hence, we can simply load movie plots and the rating data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bP9jY6dl5GQF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data from https://static.preferred.ai/cornac/datasets/movielens/ml_plot.zip\n",
            "will be cached into C:\\Users\\Rachid\\.cornac\\movielens/ml_plot.dat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3.60MB [00:05, 680kB/s]                             \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unzipping ...\n",
            "File cached!\n"
          ]
        }
      ],
      "source": [
        "plots, movie_ids = movielens.load_plot()\n",
        "\n",
        "# movies without plots are filtered out by `cornac.data.Reader`\n",
        "ml_100k = movielens.load_feedback(reader=Reader(item_set=movie_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('196', '242', 3.0),\n",
              " ('186', '302', 3.0),\n",
              " ('22', '377', 1.0),\n",
              " ('244', '51', 2.0),\n",
              " ('166', '346', 1.0)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_100k[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a\\tlittle\\tboy\\tname\\tandy\\tlove\\tto\\tbe\\tin\\the\\troom\\tplay\\twith\\the\\ttoy\\tespecially\\the\\tdoll\\tname\\twoody\\tbut\\twhat\\tdo\\tthe\\ttoy\\tdo\\twhen\\tandy\\tbe\\tnot\\twith\\tthey\\tthey\\tcome\\tto\\tlife\\twoody\\tbelieve\\tthat\\the\\thave\\tlife\\tas\\ta\\ttoy\\tgood\\thowever\\the\\tmust\\tworry\\tabout\\tandy\\tfamily\\tmoving\\tand\\twhat\\twoody\\tdo\\tnot\\tknow\\tbe\\tabout\\tandy\\tbirthday\\tparty\\twoody\\tdo\\tnot\\trealize\\tthat\\tandy\\tmother\\tgive\\the\\ta\\taction\\tfigure\\tknow\\tas\\tbuzz\\tlightyear\\twho\\tdo\\tnot\\tbelieve\\tthat\\the\\tbe\\ta\\ttoy\\tand\\tquickly\\tbecome\\tandy\\tnew\\tfavorite\\ttoy\\twoody\\twho\\tbe\\tnow\\tconsume\\twith\\tjealousy\\ttry\\tto\\tget\\trid\\tof\\tbuzz\\tthen\\tboth\\twoody\\tand\\tbuzz\\tbe\\tnow\\tlose\\tthey\\tmust\\tfind\\ta\\tway\\tto\\tget\\tback\\tto\\tandy\\tbefore\\the\\tmove\\twithout\\tthey\\tbut\\tthey\\twill\\thave\\tto\\tpass\\tthrough\\ta\\truthless\\ttoy\\tkiller\\tsid\\tphillips\\t|toy\\tstory\\tbe\\tabout\\tthe\\tsecret\\tlife\\tof\\ttoy\\twhen\\tpeople\\tbe\\tnot\\taround\\twhen\\tbuzz\\tlightyear\\ta\\ttake\\twoody\\tplace\\tas\\tandy\\tfavorite\\ttoy\\twoody\\tdo\\tnot\\tlike\\tthe\\tsituation\\tand\\tget\\tinto\\ta\\tfight\\twith\\tbuzz\\taccidentaly\\tbuzz\\tfall\\tout\\tthe\\twindow\\tand\\twoody\\tbe\\taccuse\\tby\\tall\\tthe\\tother\\ttoy\\tof\\thave\\tkill\\the\\the\\thave\\tto\\tgo\\tout\\tof\\tthe\\thouse\\tto\\tlook\\tfor\\the\\tso\\tthat\\tthey\\tcan\\tboth\\treturn\\tto\\tandys\\troom\\tbut\\twhile\\ton\\tthe\\toutside\\tthey\\tget\\tinto\\tall\\tkind\\tof\\ttrouble\\twhile\\ttry\\tto\\tget\\thome\\t|imagination\\trun\\trampant\\twhen\\ttoy\\tbecome\\tmobile\\twhen\\tnot\\twatch\\ttwo\\ttoy\\twoody\\tand\\tbuzz\\tlightyear\\tdespise\\teach\\tother\\tlike\\tno\\tother\\tbut\\twhen\\tthe\\ttoy\\tbe\\tseparate\\tfrom\\tthey\\thome\\ta\\ttruce\\tbe\\tform\\tbetween\\tthey\\tall\\tin\\ta\\teffort\\tto\\tjourney\\thome\\t|a\\ttoy\\tname\\twoody\\thave\\tit\\tall\\the\\tbe\\tpractically\\tthe\\tleader\\tin\\tandy\\ttoy\\troom\\tbo\\tpeep\\thave\\tthe\\thot\\tfor\\the\\tand\\tmost\\timportantly\\the\\tbe\\tandy\\tfavorite\\ttoy\\tbut\\twhen\\tthe\\tclock\\tstrike\\tandy\\tbirthday\\ta\\tnew\\ttoy\\tarrive\\tbuzz\\tlightyear\\ta\\tspace\\tcadet\\twho\\tthink\\the\\tbe\\ta\\tspace\\tranger\\tnot\\ta\\ttoy\\tin\\ta\\troom\\tinstantly\\twin\\tover\\tandy\\tthus\\tbecome\\tandy\\tnew\\ttreasure\\tbut\\twhen\\twoody\\tbe\\taccuse\\tof\\tknock\\tbuzz\\tout\\tof\\tthe\\twindow\\the\\tmust\\tgo\\tinto\\tthe\\tworld\\tand\\tfind\\tbuzz\\twith\\tmany\\tdelay\\t|andy\\tdavis\\tbe\\ta\\tordinary\\tboy\\tor\\tso\\the\\tthink\\the\\tbaby\\tsister\\tmother\\tand\\the\\tlive\\tin\\ta\\tnice\\tlittle\\thouse\\tthe\\tonly\\tproblem\\tthat\\tandy\\tdo\\tnot\\tknow\\tabout\\tbe\\the\\ttoy\\tafter\\the\\tplay\\twith\\tthey\\tthey\\tcome\\tto\\tlife\\twoody\\tbo\\tpeep\\trex\\tslinky\\tpotato\\thead\\thamm\\tlenny\\tslinky\\tspell\\tand\\ta\\tfew\\tother\\tbe\\the\\ttoy\\tthen\\tas\\ta\\trivalry\\tbegin\\tbetween\\twoody\\tand\\tnew\\ttoy\\tbuzz\\t|',\n",
              " 'after\\tbe\\ttrap\\tin\\ta\\tjungle\\tboard\\tgame\\tfor\\t26\\tyear\\ta\\twin\\the\\trelease\\tfrom\\tthe\\tgame\\tbut\\tno\\tsooner\\thave\\the\\tarrive\\tthat\\the\\tbe\\tforce\\tto\\tplay\\tagain\\tand\\tthis\\ttime\\tset\\tthe\\tcreature\\tof\\tthe\\tjungle\\tloose\\ton\\tthe\\tcity\\tnow\\tit\\tbe\\tup\\tto\\the\\tto\\tstop\\tthey\\t|alan\\tparris\\thave\\tbe\\ttrap\\tin\\ta\\tancient\\tmagical\\tboard\\tgame\\tjumanji\\tfor\\t25\\tyear\\twhen\\the\\tbe\\tfinally\\tfree\\tby\\ttwo\\tchild\\ta\\therd\\tof\\twild\\texotic\\tanimal\\thave\\taccidentally\\tbe\\trelease\\tas\\twell\\tnow\\talan\\tmust\\ttry\\tto\\tsave\\the\\thometown\\tfrom\\tdestruction\\t|old\\talan\\tparrish\\tfind\\tjumanji\\ta\\tboard\\tgame\\tin\\t1969\\the\\tand\\tsarah\\twhittle\\tplay\\tit\\tthat\\tnight\\twhen\\ta\\tquote\\tsay\\tin\\tthe\\tjungle\\tyou\\tmust\\twait\\tuntil\\tthe\\tdice\\troll\\t5\\tor\\t8\\talan\\tbe\\tsuddenly\\tpull\\tinto\\tthe\\tgame\\tyear\\tlater\\ttwo\\tmore\\tkid\\tfind\\tthis\\tgame\\tone\\tof\\tthey\\troll\\ta\\t5\\tand\\talan\\tparrish\\tcome\\tback\\tbut\\the\\tbe\\tsoon\\tforce\\tto\\tfind\\tsarah\\tand\\tfinish\\tthe\\tgame\\t|when\\tyoung\\talan\\tparrish\\tdiscover\\ta\\tmysterious\\tboard\\tgame\\the\\tdo\\tnot\\trealize\\tits\\tunimaginable\\tpower\\tuntil\\the\\tbe\\tmagically\\ttransport\\tbefore\\tthe\\tstartled\\teye\\tof\\the\\tfriend\\tsarah\\tinto\\tthe\\tuntame\\tjungle\\tof\\tjumanji\\tthere\\the\\tremain\\tfor\\t26\\tyear\\tuntil\\the\\tbe\\tfree\\tfrom\\tthe\\tgame\\tspell\\tby\\ttwo\\tunsuspecting\\tchild\\tnow\\ta\\tgrown\\tman\\talan\\treunite\\twith\\tsarah\\tand\\ttogether\\twith\\tjudy\\tand\\tpeter\\ttry\\tto\\toutwit\\tthe\\tgame\\tpowerful\\tforce\\t|',\n",
              " 'thing\\tdo\\tnot\\tseem\\tto\\tchange\\tmuch\\tin\\twabasha\\tcounty\\tmax\\tand\\tjohn\\tbe\\tstill\\tfight\\tafter\\t35\\tyear\\tgrandpa\\tstill\\tdrink\\tsmoke\\tand\\tchase\\twoman\\tand\\tnobody\\tbe\\table\\tto\\tcatch\\tthe\\tfabled\\tcatfish\\thunter\\ta\\tgigantic\\tcatfish\\tthat\\tactually\\tsmile\\tat\\tfisherman\\twho\\ttry\\tto\\tsnare\\tit\\tsix\\tmonth\\tago\\tjohn\\tmarry\\tthe\\tnew\\tgirl\\tin\\ttown\\tariel\\tand\\tpeople\\tbegin\\tto\\tsuspect\\tthat\\tmax\\tmight\\tbe\\tmiss\\tsomething\\tsimilar\\tin\\the\\tlife\\tthe\\tonly\\tjoy\\tmax\\tclaim\\tbe\\tleave\\tin\\the\\tlife\\tbe\\tfishing\\tbut\\tthat\\tmight\\tchange\\twith\\tthe\\tnew\\towner\\tof\\tthe\\tbait\\tshop\\t|',\n",
              " 'this\\tstory\\tbase\\ton\\tthe\\tbest\\tselling\\tnovel\\tby\\tterry\\tmcmillan\\tfollow\\tthe\\tlife\\tof\\tfour\\twoman\\tas\\tthey\\ttry\\tto\\tdeal\\twith\\tthey\\tvery\\tlive\\tfriendship\\tbecome\\tthe\\tstrongest\\tbond\\tbetween\\tthese\\twoman\\tas\\tman\\tcareer\\tand\\tfamily\\ttake\\tthey\\tin\\tdifferent\\tdirection\\toften\\tthis\\tmovie\\tspeak\\tabout\\tsome\\tof\\tthe\\tproblem\\tand\\tstruggle\\tthe\\tmodern\\twoman\\tface\\tin\\ttoday\\tworld\\t|',\n",
              " 'in\\tthis\\tsequel\\tto\\tfather\\tof\\tthe\\tbride\\tgeorge\\tbanks\\tmust\\taccept\\tthe\\treality\\tof\\twhat\\the\\tdaughter\\tascension\\tfrom\\tdaughter\\tto\\twife\\tand\\tnow\\tto\\tmother\\tmean\\twhen\\tplace\\tinto\\tperspective\\tagainst\\the\\town\\tstage\\tof\\tlife\\tas\\tthe\\tcomfortable\\tfamily\\tunit\\tstart\\tto\\tunravel\\tin\\the\\tmind\\ta\\trapid\\tprogression\\tinto\\tcrisis\\tbe\\tin\\the\\tfuture\\the\\tjourney\\tto\\tregain\\the\\tyouth\\tact\\tas\\ta\\tcatalyst\\tfor\\ta\\tkind\\tof\\trebirth\\tof\\the\\tattitude\\ton\\tlife\\twhen\\the\\tand\\the\\twife\\tnina\\tfind\\thow\\tthey\\tlife\\tbe\\tabout\\tto\\tchange\\tas\\twell\\t|family\\ttrouble\\tcontinue\\tto\\tplague\\tgeorge\\tbanks\\thave\\tsurvive\\the\\tdaughter\\tmarriage\\tin\\tthe\\tfirst\\tfilm\\the\\tmust\\tnow\\tdeal\\twith\\tshe\\tpregnancy\\tto\\tcomplicate\\tmatter\\the\\twife\\tnina\\tbe\\tpregnant\\tas\\twell\\t|']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plots[:5]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "43wktekd5GQJ"
      },
      "source": [
        "## Cross modality\n",
        "\n",
        "To get vector representations from text data, we build a `TextModality` using our corpus and corresponding ids. We also need to supply a `Tokenizer` for text splitting, in this case tokens are seperated by `\\tab` character. We limit the maximum size of vocabulary to 5000, which also means the dimension of our vector space cannot go higher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0VHNg6tm5GQK"
      },
      "outputs": [],
      "source": [
        "item_text_modality = TextModality(corpus=plots, ids=movie_ids, \n",
        "                                  tokenizer=BaseTokenizer(sep='\\t', stop_words='english'),\n",
        "                                  max_vocab=5000, max_doc_freq=0.5).build()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xGYc5L7e5GQS"
      },
      "source": [
        "Next step is to create an `ImageModality`, which is use by VBPR, using our text representations. In this case, we take the word-count matrix to substitute for visual features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gUGJ5AjI5GQU"
      },
      "outputs": [],
      "source": [
        "features = item_text_modality.count_matrix.A\n",
        "item_image_modality = ImageModality(features=features, ids=movie_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rkxw-D_m5GQY"
      },
      "source": [
        "In Cornac, every model relies on the modality for which it was designed for (i.e., visual recommendation algorithms always work with `ImageModality`). This ensures consistency with models' original assumptions, and helps us avoid confusions regarding which modality to use when integrating a new recommender model.\n",
        "\n",
        "## Experiment\n",
        "\n",
        "We employ the `RatioSplit` evaluation method to split the rating data. The `item_image_modality` is also supplied here for later usage by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cc66mPy35GQZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rating_threshold = 1.0\n",
            "exclude_unknowns = True\n",
            "---\n",
            "Training data:\n",
            "Number of users = 926\n",
            "Number of items = 1162\n",
            "Number of ratings = 9480\n",
            "Max rating = 5.0\n",
            "Min rating = 1.0\n",
            "Global mean = 3.5\n",
            "---\n",
            "Test data:\n",
            "Number of users = 926\n",
            "Number of items = 1162\n",
            "Number of ratings = 82993\n",
            "Number of unknown users = 0\n",
            "Number of unknown items = 0\n",
            "---\n",
            "Total users = 926\n",
            "Total items = 1162\n"
          ]
        }
      ],
      "source": [
        "ratio_split = RatioSplit(data=ml_100k, test_size=0.9,\n",
        "                         item_image=item_image_modality,\n",
        "                         exclude_unknowns=True, \n",
        "                         verbose=True, seed=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bKalGw5x5GQe"
      },
      "source": [
        "We are now ready to evaluate performance of VBPR. The [BPR](https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf) model is also included as a baseline to examine the effectiveness of the text auxiliary data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rczsfDrO5GQg"
      },
      "outputs": [],
      "source": [
        "vbpr = cornac.models.VBPR(k=10, k2=10, n_epochs=20, batch_size=10, learning_rate=0.001,\n",
        "                          lambda_w=1.0, lambda_b=0.0, lambda_e=100.0, use_gpu=True, seed=123)\n",
        "\n",
        "bpr = cornac.models.BPR(k=10, max_iter=100, learning_rate=0.001, lambda_reg=0.001, seed=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "giDcupSL5GQk"
      },
      "outputs": [],
      "source": [
        "auc = cornac.metrics.AUC()\n",
        "rec_50 = cornac.metrics.Recall(k=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yes6tv-15GQo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[BPR] Training started!\n",
            "\n",
            "[BPR] Evaluation started!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ranking: 100%|██████████| 926/926 [00:01<00:00, 605.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[VBPR] Training started!\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m cornac\u001b[39m.\u001b[39;49mExperiment(eval_method\u001b[39m=\u001b[39;49mratio_split,\n\u001b[0;32m      2\u001b[0m                   models\u001b[39m=\u001b[39;49m[bpr, vbpr],\n\u001b[1;32m----> 3\u001b[0m                   metrics\u001b[39m=\u001b[39;49m[auc, rec_50])\u001b[39m.\u001b[39;49mrun()\n",
            "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\envs\\cornac\\Lib\\site-packages\\cornac\\experiment\\experiment.py:142\u001b[0m, in \u001b[0;36mExperiment.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m         model\u001b[39m.\u001b[39mverbose \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose\n\u001b[0;32m    141\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels:\n\u001b[1;32m--> 142\u001b[0m     test_result, val_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_method\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m    143\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m    144\u001b[0m         metrics\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetrics,\n\u001b[0;32m    145\u001b[0m         user_based\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muser_based,\n\u001b[0;32m    146\u001b[0m         show_validation\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshow_validation,\n\u001b[0;32m    147\u001b[0m     )\n\u001b[0;32m    149\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresult\u001b[39m.\u001b[39mappend(test_result)\n\u001b[0;32m    150\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\envs\\cornac\\Lib\\site-packages\\cornac\\eval_methods\\base_method.py:734\u001b[0m, in \u001b[0;36mBaseMethod.evaluate\u001b[1;34m(self, model, metrics, user_based, show_validation)\u001b[0m\n\u001b[0;32m    731\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m[\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m] Training started!\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(model\u001b[39m.\u001b[39mname))\n\u001b[0;32m    733\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 734\u001b[0m model\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_set, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mval_set)\n\u001b[0;32m    735\u001b[0m train_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start\n\u001b[0;32m    737\u001b[0m \u001b[39m##############\u001b[39;00m\n\u001b[0;32m    738\u001b[0m \u001b[39m# EVALUATION #\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[39m##############\u001b[39;00m\n",
            "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\envs\\cornac\\Lib\\site-packages\\cornac\\models\\vbpr\\recom_vbpr.py:165\u001b[0m, in \u001b[0;36mVBPR.fit\u001b[1;34m(self, train_set, val_set)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init(\n\u001b[0;32m    159\u001b[0m     n_users\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_users,\n\u001b[0;32m    160\u001b[0m     n_items\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_items,\n\u001b[0;32m    161\u001b[0m     features\u001b[39m=\u001b[39mtrain_features,\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainable:\n\u001b[1;32m--> 165\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_torch(train_set, train_features)\n\u001b[0;32m    167\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\envs\\cornac\\Lib\\site-packages\\cornac\\models\\vbpr\\recom_vbpr.py:170\u001b[0m, in \u001b[0;36mVBPR._fit_torch\u001b[1;34m(self, train_set, train_features)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit_torch\u001b[39m(\u001b[39mself\u001b[39m, train_set, train_features):\n\u001b[1;32m--> 170\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m    172\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m_l2_loss\u001b[39m(\u001b[39m*\u001b[39mtensors):\n\u001b[0;32m    173\u001b[0m         l2_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "cornac.Experiment(eval_method=ratio_split,\n",
        "                  models=[bpr, vbpr],\n",
        "                  metrics=[auc, rec_50]).run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Nbplrac5GQs"
      },
      "source": [
        "Results after running the experiment:\n",
        "\n",
        "<pre>\n",
        "TEST:\n",
        "...\n",
        "     |    AUC | Recall@50 | Train (s) | Test (s)\n",
        "---- + ------ + --------- + --------- + --------\n",
        "BPR  | 0.8073 |    0.2301 |    0.2390 |   1.1167\n",
        "VBPR | 0.8219 |    0.2519 |  113.8606 |   1.0624\n",
        "</pre>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "vbpr_text.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
