{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a4225b-1a05-4b58-9e1d-1511650ef225",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hnswlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6bb9a5-ffb5-4221-8122-9aa286af1d9c",
   "metadata": {},
   "source": [
    "## Recommender model training\n",
    "\n",
    "We do a small experiment to demonstrate how Approximate Nearest Neighbor (ANN) search could be performed in Cornac. First, we need to train a model that supports ANN search. Here we choose MF for simple illustration purpose. Other models that support ANN search should work in a similar fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a0c130-7dd7-4004-a613-5b123dcc75d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating_threshold = 1.0\n",
      "exclude_unknowns = True\n",
      "---\n",
      "Training data:\n",
      "Number of users = 9986\n",
      "Number of items = 4927\n",
      "Number of ratings = 547022\n",
      "Max rating = 1.0\n",
      "Min rating = 1.0\n",
      "Global mean = 1.0\n",
      "---\n",
      "Test data:\n",
      "Number of users = 9986\n",
      "Number of items = 4927\n",
      "Number of ratings = 60753\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Total users = 9986\n",
      "Total items = 4927\n",
      "\n",
      "[MF] Training started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1565ff1ab5304ec48e500258ac445394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n",
      "\n",
      "[MF] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6a9948337149568a296c65e72943da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/8214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "   |    AUC | Recall@20 | Train (s) | Test (s)\n",
      "-- + ------ + --------- + --------- + --------\n",
      "MF | 0.8542 |    0.0591 |    1.0683 |  11.7926\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cornac\n",
    "from cornac.data import Reader\n",
    "from cornac.datasets import netflix\n",
    "from cornac.eval_methods import RatioSplit\n",
    "\n",
    "data = netflix.load_feedback(variant=\"small\", reader=Reader(bin_threshold=1.0))\n",
    "\n",
    "ratio_split = RatioSplit(\n",
    "    data=data,\n",
    "    test_size=0.1,\n",
    "    rating_threshold=1.0,\n",
    "    exclude_unknowns=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "mf = cornac.models.MF(\n",
    "    k=50, \n",
    "    max_iter=25, \n",
    "    learning_rate=0.01, \n",
    "    lambda_reg=0.02, \n",
    "    use_bias=False,\n",
    "    verbose=True,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "auc = cornac.metrics.AUC()\n",
    "rec_20 = cornac.metrics.Recall(k=20)\n",
    "\n",
    "cornac.Experiment(\n",
    "    eval_method=ratio_split,\n",
    "    models=[mf],\n",
    "    metrics=[auc, rec_20],\n",
    "    user_based=True,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b5236-1a94-43a9-bfb9-6dc4623bb33c",
   "metadata": {},
   "source": [
    "## Building index for ANN recommender\n",
    "\n",
    "After MF model is trained, we need to wrap it with an ANN recommender. We employ Cornac built-in HNSWLibANN which implements [HNSW algorithm](https://arxiv.org/abs/1603.09320) for building index and doing approximate K-nearest neighbor search. More on how to tune the hyper-parameters at https://github.com/nmslib/hnswlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa280b9d-ec04-41eb-9de2-acfb67fbeb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cornac.models import HNSWLibANN\n",
    "\n",
    "ann = HNSWLibANN(\n",
    "    recom=mf,\n",
    "    M=16,\n",
    "    ef_construction=100,\n",
    "    ef=50,\n",
    "    num_threads=-1,\n",
    ")\n",
    "ann.build_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67fe0eb-7ca5-4ff9-87a5-a34ab612036e",
   "metadata": {},
   "source": [
    "## Time/accuracy tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1846494-e618-48ef-b489-45d02e0d5430",
   "metadata": {},
   "source": [
    "Here we measure the tradeoff between efficiency and accuracy. Let say we are doing top-20 recommendations for 10,000 users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c5f959-f706-4406-85c9-a4acf2ac20c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "K = 20\n",
    "N = 10000\n",
    "test_users = np.random.choice(mf.user_ids, size=N)\n",
    "mf_recs = []\n",
    "ann_recs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6730a93f-729d-4bea-b5aa-8fb9d9cef867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 12s, sys: 51.4 ms, total: 3min 12s\n",
      "Wall time: 6.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for uid in test_users:\n",
    "    mf_recs.append(mf.recommend(uid, k=K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "520da23e-79eb-4c53-9aaa-a33aaea883fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 358 ms, sys: 0 ns, total: 358 ms\n",
      "Wall time: 354 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for uid in test_users:\n",
    "    ann_recs.append(ann.recommend(uid, k=K))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f4f68a-c69b-4e70-b32a-81eb78d21279",
   "metadata": {},
   "source": [
    "While it took MF 6.05 seconds to complete the task, it's only 354 ms for ANN. The speed up is about 20 times. Note that our dataset contains less than 5000 items. We will see an even bigger improvement with more items and with higher dimensions of the factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9e5dde7-8012-44e7-b407-d7140047c576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.95049999999999\n"
     ]
    }
   ],
   "source": [
    "recalls = []\n",
    "for mf_rec, ann_rec in zip(mf_recs, ann_recs):\n",
    "    recalls.append(len(set(mf_rec) & set(ann_rec[0])) / len(mf_rec))\n",
    "print(np.mean(recalls) * 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf472812-70c8-4146-b61c-b3c1f5c5b0a5",
   "metadata": {},
   "source": [
    "In terms of recall, we only see a small drop of 2% meaning recommendations are very similar between the two. While it's almost a free lunch for this case, the numbers might differ for other cases. It's always good to make sure that ANN maintains consistent recommendations with the base model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cornac",
   "language": "python",
   "name": "cornac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
